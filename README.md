# wiki-dump-archiver

Simple Python tool to:
- Download Wikimedia shorturls dump
- Extract URLs
- Fetch and archive page content into a local SQLite database

âœ… Dumps can be downloaded from:  
https://dumps.wikimedia.org/other/shorturls/

---

## ğŸš€ Features
- Automatic download of `.gz` dump if not present locally
- Extract URLs from dump
- Fetch page HTML content
- Detect changes using SHA-256 hash
- Save pages to a local SQLite database (`data/wiki_pages.db`)

---

## âš™ï¸ Installation
```bash
git clone https://github.com/leomaxuz/wiki-dump-archiver.git
cd wiki-dump-archiver
pip install -r requirements.txt
